{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ground_truth=['students','university','tuition','opportunities']\n",
    "##tokens = ['Finland','Departmet','School','Computing','University', 'UEF', 'Science','Park', 'Joensuu']\n",
    "#pred=['studies','universities','lecture','chances','free']\n",
    "\n",
    "ground_truth=['Finland','University', 'Forest', 'Lake']\n",
    "#tokens = ['Finland','Departmet','School','Computing','University', 'UEF', 'Science','Park', 'Joensuu']\n",
    "pred=['University','College', 'School','Research','Institute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "students\n",
      "university\n",
      "tuition\n",
      "opportunities\n"
     ]
    }
   ],
   "source": [
    "for tk in ground_truth:\n",
    "    print (tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.23) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model=word2vec.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score2(list1,list2):\n",
    "    sc2=[]\n",
    "    for tk in list1:\n",
    "        i =0\n",
    "        sc=[]\n",
    "        for tk_2 in list2:\n",
    "            #ps.stem(w)\n",
    "            t1 = tk\n",
    "            t2 = tk_2\n",
    "            sim =model.similarity(t1,t2)\n",
    "            print(tk,tk_2, sim)\n",
    "            sc.append(sim)\n",
    "            i = i + 1\n",
    "        sc=np.array(sc)\n",
    "        sc2.append(np.max(sc,axis=0))\n",
    "    return sc2\n",
    "\n",
    "def get_score(list1,list2):\n",
    "    sc2=[]\n",
    "    for tk in list1:\n",
    "        i =0\n",
    "        sc=[]\n",
    "        for tk_2 in list2:\n",
    "            #ps.stem(w)\n",
    "            try:\n",
    "                t1 =ps.stem(wl.lemmatize(tk))\n",
    "                t2 = ps.stem(wl.lemmatize(tk_2))\n",
    "                sim =model.similarity(t1,t2)\n",
    "            except KeyError:\n",
    "                t1 = tk\n",
    "                t2 = tk_2\n",
    "                sim =model.similarity(t1,t2)\n",
    "            print(tk,tk_2, sim)\n",
    "            sc.append(sim)\n",
    "            i = i + 1\n",
    "        sc=np.array(sc)\n",
    "        sc2.append(np.max(sc,axis=0))\n",
    "    return sc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_score2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-837b2c0f4888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_score2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_score2' is not defined"
     ]
    }
   ],
   "source": [
    "get_score2(pred,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University Finland 0.091112964\n",
      "University University 0.99999994\n",
      "University Forest 0.14429793\n",
      "University Lake 0.12755406\n",
      "College Finland -0.021328468\n",
      "College University 0.6669972\n",
      "College Forest 0.24965516\n",
      "College Lake 0.12299147\n",
      "School Finland -0.0018103165\n",
      "School University 0.44459668\n",
      "School Forest 0.21245177\n",
      "School Lake 0.15821028\n",
      "Research Finland 0.10672594\n",
      "Research University 0.31817865\n",
      "Research Forest 0.09706756\n",
      "Research Lake 0.044050373\n",
      "Institute Finland 0.053941496\n",
      "Institute University 0.50452447\n",
      "Institute Forest 0.09517212\n",
      "Institute Lake 0.07636163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5868593871593475"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_softP(pred_scores):\n",
    "    sum1=0\n",
    "    for tk_score in pred_scores:\n",
    "        sum1= sum1 + tk_score\n",
    "        \n",
    "    return sum1/len(pred_scores)\n",
    "\n",
    "get_softP(get_score2(pred,ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finland University 0.091112964\n",
      "Finland College -0.021328468\n",
      "Finland School -0.0018103165\n",
      "Finland Research 0.10672594\n",
      "Finland Institute 0.053941496\n",
      "University University 0.99999994\n",
      "University College 0.6669972\n",
      "University School 0.44459668\n",
      "University Research 0.31817865\n",
      "University Institute 0.50452447\n",
      "Forest University 0.14429793\n",
      "Forest College 0.24965516\n",
      "Forest School 0.21245177\n",
      "Forest Research 0.09706756\n",
      "Forest Institute 0.09517212\n",
      "Lake University 0.12755406\n",
      "Lake College 0.12299147\n",
      "Lake School 0.15821028\n",
      "Lake Research 0.044050373\n",
      "Lake Institute 0.07636163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37864782847464085"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_softR(gt_scores):\n",
    "    sum1=0\n",
    "    for tk_score in gt_scores:\n",
    "        sum1= sum1 + tk_score\n",
    "        \n",
    "    return sum1/len(gt_scores)\n",
    "get_softP(get_score2(ground_truth,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'string']\n"
     ]
    }
   ],
   "source": [
    "test= \"This is a test string\"\n",
    "test2 = test.split()\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(tokens,ground_truth):\n",
    "    sc2=[]\n",
    "    for tk in tokens:\n",
    "        i =0\n",
    "        sc=[]\n",
    "        for tk_2 in ground_truth:\n",
    "            try:\n",
    "                sim =model.similarity(tk,tk_2)\n",
    "                print(i,tk,tk_2, sim)\n",
    "                sc.append(sim)\n",
    "                i = i + 1\n",
    "            except KeyError:\n",
    "                sc.append(0)\n",
    "                i = i + 1\n",
    "        sc=np.array(sc)\n",
    "        sc2.append(np.max(sc,axis=0))\n",
    "    return sc2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
